{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0607f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ff45e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tweets from our repo\n",
    "data = pd.read_csv(r\"../inputdata/cnnhealth.txt\", sep=\"|\", header=None, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "930e3c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in its unedited state: \n",
      "                       0                               1  \\\n",
      "0     576880531301801984  Sat Mar 14 23:00:11 +0000 2015   \n",
      "1     576820122666471424  Sat Mar 14 19:00:08 +0000 2015   \n",
      "2     576744652717461504  Sat Mar 14 14:00:15 +0000 2015   \n",
      "3     576736754436304896  Sat Mar 14 13:28:52 +0000 2015   \n",
      "4     576736614766010368  Sat Mar 14 13:28:18 +0000 2015   \n",
      "...                  ...                             ...   \n",
      "4040  239699936671854593  Sun Aug 26 12:24:52 +0000 2012   \n",
      "4041  239504620710420480  Sat Aug 25 23:28:46 +0000 2012   \n",
      "4042  239410205757145088  Sat Aug 25 17:13:35 +0000 2012   \n",
      "4043  239386320416428032  Sat Aug 25 15:38:41 +0000 2012   \n",
      "4044  239366825018806272  Sat Aug 25 14:21:12 +0000 2012   \n",
      "\n",
      "                                                      2  \n",
      "0     An abundance of online info can turn us into e...  \n",
      "1     A plant-based diet that incorporates fish may ...  \n",
      "2     It doesn't take much to damage your hearing at...  \n",
      "3     RT @CNN: Forever young? Discover this islandâ€™s...  \n",
      "4     RT @CNN: Is post-traumatic stress disorder in ...  \n",
      "...                                                 ...  \n",
      "4040  RT @EverydayHealth: Want killer abs? @JillianM...  \n",
      "4041  Medicare at stake -- @sanjayguptaCNN talks abo...  \n",
      "4042  Ann Romney talks about her experience with MS ...  \n",
      "4043  Make sure your first marathon isn't your last!...  \n",
      "4044  Robin Roberts' cancer diagnosis http://at.cnn....  \n",
      "\n",
      "[4045 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data in its unedited state: \")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "11977f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing urls from our tweets. One potential way to remove non-meaningful information such as server locations from the url\n",
    "## path. Another potential method could be adding appearance thresholds for certain words i.e. if B8VAgxHCYAETD6L.jpg does not\n",
    "## appear more than once, then remove it from our pool. There may be some meaningful information lost when removing the\n",
    "## url. Nearly all tweets have embedded links for cnn.com, so keeping those will not help us better classify/differentiate the\n",
    "## tweets. However, some are for pbs, instagram, etc. so could prove meaningful as a differentiator for clustering.\n",
    "data[2] = data[2].replace('(https?:\\/\\/)(?:([^\\n ]*))?', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "1ee64ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take tweets column from dataframa and convert it to an array so we can preform vector operations on it\n",
    "tweets = data[2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8667d2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An abundance of online info can turn us into e-hypochondriacs. Or, worse, lead us to neglect getting the care we need '\n",
      " 'A plant-based diet that incorporates fish may be the key to preventing colorectal cancers:  '\n",
      " \"It doesn't take much to damage your hearing at a sports bar or nightclub. That's why a billion people are at risk. \"\n",
      " ... 'Ann Romney talks about her experience with MS '\n",
      " \"Make sure your first marathon isn't your last! \"\n",
      " \"Robin Roberts' cancer diagnosis \"]\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "db23b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create count vectorizer, passing the standard english stop words set as a parameter (removes words such as 'and', 'it' and punctuation, etc.)\n",
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "1184948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "9c332948",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## get array of unique words across all documents\n",
    "names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0f308b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4045x7554 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 31043 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get feature ve\n",
    "features = vectorizer.transform(tweets)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4cdfb675",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurearray = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "fd4d5f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(featurearray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "41ac88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(featurearray, columns=names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "f580398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'../outputdata/featurematrix.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5944e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
